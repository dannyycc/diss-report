\begin{appendices}
\addcontentsline{toc}{section}{Appendices}


%\section{The Flux Sketch}
%\includegraphics[width=\textwidth]{Report/Appendices/flux_sketch.jpg}
%\label{appx: Flux Sketch}

\section{Ethical Approval}
\begin{lstlisting}[language={}]
Dear 2054584,

Warwick ID Number: 2054584 

This is to confirm that your Supervisor's Delegated Approval form has been received by the WMG Full-time Student Office, Detecting IEEE 802.11 Attacks using Machine Learning does NOT require ethical approval.

You are reminded that you must now adhere to the answers and detail given in the completed WMG SDA ethical approval form (and associated documentation) within your research project. If anything changes in your research such that any of your answers change, then you must contact us to check if you need to reapply for or update your ethical approval before you proceed.

If your data collection strategy, including the detail of any interview/ survey questions that you drafted changes substantially prior to or during data collection, then you must reapply for ethical approval before your changes are implemented. 

When you submit your project please write N/A against the ethical approval field in the submission pro-forma and include a copy of this email in the appendices of your project.

Kind regards

Jade Barrett
\end{lstlisting}

\newpage
\section{Dataset Manipulation}

\subsection{CSV Combiner Script}
\label{appx: CSV Combiner Script}
\begin{lstlisting}[language=bash, literate={-}{-}1]
#!/bin/bash

# Input Directory
input_dir="../Malware"

cd "$input_dir"

# Set the output file name
output_file="combined.csv"

# Check if the output file already exists and delete it
if [ -f "$output_file" ]; then
  rm "$output_file"
fi

# Print a status message
echo "Combining files..."

# Loop through all the files that match the pattern reduced_*.csv
for file in $(ls *.csv | sort -V)
do
  # Check if the file exists
  if [ -f "$file" ]; then
    # Print a status message
    echo "Combining $file..."

# If this is the first file, copy the header to the output file
    if [ ! -f "$output_file" ]; then
      head -n 1 "$file" > "$output_file"
    fi

    # Append all the rows except the header to the output file
    tail -n +2 "$file" >> "$output_file"
  fi
done

# Print a status message
echo "Done."
\end{lstlisting}

\newpage
\subsection{Feature Extraction \& Reduction}
\label{appx: Feature Extraction}

\begin{lstlisting}[language=Python]
# Define the columns to extract
cols_to_use = [
	'frame.len','radiotap.dbm_antsignal','radiotap.length', 
	'wlan.duration','wlan_radio.duration','wlan_radio.signal_dbm', 
	'radiotap.present.tsft','wlan.fc.type','wlan.fc.subtype', 
	'wlan.fc.ds','wlan.fc.frag','wlan.fc.moredata',
	'wlan.fc.protected','wlan.fc.pwrmgt','wlan.fc.retry',
	'wlan_radio.phy','udp.length','ip.ttl',
	'arp','arp.proto.type','arp.hw.size',
	'arp.proto.size','arp.hw.type','arp.opcode',
  'tcp.analysis','tcp.analysis.retransmission','tcp.option_len',
  'tcp.checksum.status','tcp.flags.ack','tcp.flags.fin',
  'tcp.flags.push','tcp.flags.reset','tcp.flags.syn',
  'dns','dns.count.queries','dns.count.answers',
  'dns.resp.len','dns.resp.ttl','http.request.method',
  'http.response.code','http.content_type','ssh.message_code',
  'ssh.packet_length','nbns','nbss.length',
  'nbss.type','ldap','smb2.cmd',
  'smb.flags.response','smb.access.generic_read',
  'smb.access.generic_write','smb.access.generic_execute',
  'Label']

# Define the chunk size you want to read in each iteration
batch_size = 1000000

# Initialize an empty dataframe to hold the combined results
combined_df = pd.DataFrame()

# Iterate through the file in batches
for chunk in pd.read_csv('botnet_combined.csv', chunksize=batch_size, usecols=cols_to_use, low_memory=False):
    
    # Combine the processed chunk with previous chunks
    combined_df = pd.concat([combined_df, chunk])
\end{lstlisting}

\begin{lstlisting}[language=Python,linewidth=\textwidth]
# Drop all missing rows that contain only nan values
combined_df = combined_df.dropna(how='all')

# Drop all rows with missing values in Label Column
combined_df = combined_df.dropna(subset=['Label'])

# Fill NAs with zeros
# Change nan values to 0
combined_df = combined_df.fillna(0)
\end{lstlisting}

\newpage
\begin{lstlisting}
# Duplicate the dataframe
df = combined_df.copy()

# Regex to keep only the first value e.g 
# -100-100-10 becomes -100,   123-456-1 becomes 123, -10-2 becomes-10, 81-63-63 becomes 81
def seperated_values(x):
    x = str(x)
    match = re.match(r'^(-?\d+).*$', x)
    if match:
        return match.group(1)
    else:
        return x

# Go through all columns and change seperate values into just one value
for column in df.columns:
    df[column] = df[column].apply(seperated_values)
    print('Processing', column)
print('Done')

# Find Rows that contain values such as Oct-26, Oct-18, Feb-10 etc.. as these appear to be invalid and we will drop these rows.
regex = r"\b(?:\d{2}|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))-(?:\d{2}|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))\b"

# Use str.match method to apply the regex pattern to the column
mask = df['tcp.option_len'].astype(str).str.match(regex).fillna(False)
df = df[~mask]

mask = df['dns.resp.ttl'].astype(str).str.match(regex).fillna(False)
df = df[~mask]

mask = df['ip.ttl'].astype(str).str.match(regex).fillna(False)
df = df[~mask]

mask = df['smb2.cmd'].astype(str).str.match(regex).fillna(False)
df = df[~mask]

df.to_csv('Botnet_Reduced.csv', index=False)    

\end{lstlisting}

\newpage

\section{Conda Environments}
\label{appx: Conda_Env}

\subsection{Neural Networks - Apple Silicon}

\begin{lstlisting}
conda create -n nn-env python=3.9
conda activate nn-env
conda install -c apple tensorflow-deps
conda install -c conda-forge -y pandas jupyter
pip install tensorflow-macos==2.10
pip install numpy, matplotlib, scikit-learn, scipy, seaborn
\end{lstlisting}

\subsection{Classifiers}

\begin{lstlisting}
# Conda environment used for Random Forest, XGBoost and K-NN.

conda create -n ml-env python=3.9
conda activate ml-env
conda install -c conda-forge -y pandas jupyter
pip install numpy, matplotlib, scikit-learn, scipy, seaborn, xgboost
\end{lstlisting}

\newpage

\section{Data Preprocessing}
\label{appx:Data Processing}

\subsection{MinMax Scaling}
\label{appx:Scaling}

\begin{lstlisting}
# Define the scaler
scaler = MinMaxScaler()

# Fit the scaler to the following columns we define
scale_cols = [
        'frame.len',
        'radiotap.dbm_antsignal', 
        'radiotap.length', 
        'wlan.duration', 
        'wlan_radio.duration', 
        'wlan_radio.signal_dbm',
        'ip.ttl', 
        'udp.length', 
        'nbss.length',
        'dns.count.answers', 
        'dns.count.queries',
        'dns.resp.ttl',
        'ssh.packet_length']
        
# Fit the X_train and X_test
X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])
X_test[scale_cols] = scaler.transform(X_test[scale_cols])
\end{lstlisting}

\subsection{OHE Encoding}
\label{appx:OHE Encoding}
\begin{lstlisting}
cols_to_encode = [col for col in X_train.columns if col not in scale_cols]
X_all = pd.concat([X_train, X_test], axis=0)

X_all_ohe = pd.get_dummies(X_all, columns=cols_to_encode, drop_first=True, dtype=np.uint8)

# split back into train and test sets
X_train_ohe = X_all_ohe[:len(X_train)]
X_test_ohe = X_all_ohe[len(X_train):]
\end{lstlisting}

\newpage
\subsection{Label Encoding}
\label{appx:Label Encoding}
\begin{lstlisting}
    # Use Label Encoder to encode the target variable
le = LabelEncoder()

label_encoder = le.fit(y_train)
y_train_encoded = label_encoder.transform(y_train)
\end{lstlisting}

\subsection{Loading Dataset}
\label{appx:Loading Dataset}
\begin{lstlisting}
chunk_size = 1000000
dtype_opt = {
    'frame.len': 'int64',
    'radiotap.dbm_antsignal': 'int64',
    'radiotap.length': 'int64',
    'radiotap.present.tsft': 'int64',
    'wlan.duration': 'int64',
    'wlan.fc.ds': 'int64',
    'wlan.fc.frag': 'int64',
    'wlan.fc.moredata': 'int64',
    'wlan.fc.protected': 'int64',
    'wlan.fc.pwrmgt': 'int64',
    'wlan.fc.type': 'int64',
    'wlan.fc.retry': 'int64',
    'wlan.fc.subtype': 'int64',
    'wlan_radio.duration': 'int64',
    'wlan_radio.signal_dbm': 'int64',
    'wlan_radio.phy': 'int64',
    'arp': 'object',
    'arp.hw.type': 'object',
    'arp.proto.type': 'int64',
    'arp.hw.size': 'int64',
    'arp.proto.size': 'int64',
    'arp.opcode': 'int64',
    'ip.ttl': 'int64',
    'tcp.analysis': 'int64',
    'tcp.analysis.retransmission': 'int64',
    'tcp.checksum.status': 'int64',
    'tcp.flags.syn': 'int64',
    'tcp.flags.ack': 'int64',
    'tcp.flags.fin': 'int64',
    'tcp.flags.push': 'int64',
    'tcp.flags.reset': 'int64',
    'tcp.option_len': 'int64',
    'udp.length': 'int64',
    'nbns': 'object',
    'nbss.length': 'int64',
    'ldap': 'object',
    'smb2.cmd': 'int64',
    'dns': 'object',
    'dns.count.answers': 'int64',
    'dns.count.queries': 'int64',
    'dns.resp.ttl': 'int64',
    'http.content_type': 'object',
    'http.request.method': 'object',
    'http.response.code': 'int64',
    'ssh.message_code': 'int64',
    'ssh.packet_length': 'int64'
}

# Read the data
print('Reading X...')
X = pd.DataFrame()
for chunk in pd.read_csv('X.csv', chunksize=chunk_size, usecols=dtype_opt.keys(), dtype=dtype_opt, low_memory=False):
    X = pd.concat([X, chunk])

print('Reading y...')
y = pd.DataFrame()
for chunk in pd.read_csv('y.csv', chunksize=chunk_size, usecols=['Label'], dtype='object', low_memory=False):
   y = pd.concat([y, chunk])

# Split the data into training and testing sets
print('Splitting the data...')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1234, stratify=y)
\end{lstlisting}

\newpage
\section{Classifiers}
\label{appx: Classifiers}

\subsection{K-Nearest Neighbor (KNN)}
\begin{lstlisting}
# Use KNN
from sklearn.neighbors import KNeighborsClassifier

k=5

# Create KNN classifier
knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)

# Fit the model
knn.fit(X_train_ohe, y_train_encoded)

# predict the test set
y_knn_pred = knn.predict(X_test_ohe)

from sklearn.metrics import classification_report, roc_auc_score

# Get the classification report
report = classification_report(y_test_encoded, y_knn_pred)

print('Classification Report:\n', report)

# Get the all the metrics for the multi class classification

print('Accuracy: ', accuracy_score(y_test_encoded, y_knn_pred))
print('Precision: ', precision_score(y_test_encoded, y_knn_pred, average='macro'))
print('Recall: ', recall_score(y_test_encoded, y_knn_pred, average='macro'))
print('F1 Score: ', f1_score(y_test_encoded, y_knn_pred, average='macro'))

# Get the confusion matrix for multi-class and plot it
confusion = confusion_matrix(y_test, y_rf_pred)
print('Confusion Matrix\n')
print(confusion)

# Plot the confusion matrix for multi-class classification using seaborn
labels = ['Normal', 'SSDP', 'Website Spoofing', 'Malware', 'Botnet', 'SSH', 'SQL Injection']

plt.figure(figsize=(8, 8))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

plt.figure(figsize=(10, 10))
feat_importances = pd.Series(rf.feature_importances_, index=X_train_ohe.columns)
feat_importances.nlargest(20).plot(kind='barh')
plt.show()
\end{lstlisting}

\newpage

\subsection{Random Forest}
\label{appx:Random Forest}

\subsubsection{RF Model ID 0 - Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{S-CV Results}!
Mean AUC = 99.99
Mean F1 = 99.66
Mean Precision = 99.66
Mean Recall = 99.67
Mean Accuracy = 99.67
Training Time: 7795 seconds

!\textbf{Final Test Results}!
Weighted AUC: 0.9999070506312879
Weighted F1: 0.996638797834701
Weighted Precision: 0.9966379719195173
Weighted Recall: 0.9967196932696956
Accuracy: 0.9967196932696956

!\textbf{Classification Report}!
              precision    recall  f1-score   support

      Botnet       0.95      0.77      0.85     17060
      Malware      0.89      0.82      0.86     39476
      Normal       1.00      1.00      1.00     457220
      SQL          0.93      0.86      0.89     789
      SDDP         1.00      1.00      1.00     1649955
      SSH          0.94      0.79      0.86     3565
      Spoofing     0.99      0.98      0.98     121533

    accuracy                           1.00   6404584
   macro avg       0.96      0.89      0.92   6404584
weighted avg       1.00      1.00      1.00   6404584

!\textbf{Confusion Matrix}!
[[  13082      17    3957       0       0       2       2]
 [     17   32454    6994       0       0      10       1]
 [    649    3821 4565771      51       2     161    1751]
 [      0       0     113     676       0       0       0]
 [      0       0       2       0 1649953       0       0]
 [      5      20     707       0       0    2833       0]
 [      4       0    2723       0       0       0  118806]]
\end{lstlisting}

\begin{center}
	\includegraphics[scale=0.8]{Appendices/Images/RF/rf_stock_cm.png}
\end{center}


\includegraphics[width=\textwidth]{Appendices/Images/RF/rf_stock_feature_imp.png}

\newpage
\subsubsection{RF Model ID 1 - Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{S-CV Results}!
Mean AUC = 99.99
Mean F1 = 99.66
Mean Precision = 99.66
Mean Recall = 99.67
Mean Accuracy = 99.67
Training Time 7794.549654006958 seconds

!\textbf{Final Test Results}!
Test AUC: 0.9999070506312879
Weighted Test F1: 0.996638797834701
Weighted Test Precision: 0.9966379719195173
Weighted Test Recall: 0.9967196932696956
Test Accuracy: 0.9967196932696956

!\textbf{Classification Report}!
			  precision    recall  f1-score   support

      Botnet       0.95      0.77      0.85     17060
      Malware      0.89      0.82      0.86     39476
      Normal       1.00      1.00      1.00   4572206
         SQL       0.93      0.86      0.89       789
        SSDP       1.00      1.00      1.00   1649955
         SSH       0.94      0.79      0.86      3565
WebsiteSpoof       0.99      0.98      0.98    121533

    accuracy                           1.00   6404584
   macro avg       0.96      0.89      0.92   6404584
weighted avg       1.00      1.00      1.00   6404584
    
!\textbf{Confusion Matrix}!    
[[  13082      17    3957       0       0       2       2]
 [     17   32454    6994       0       0      10       1]
 [    649    3821 4565771      51       2     161    1751]
 [      0       0     113     676       0       0       0]
 [      0       0       2       0 1649953       0       0]
 [      5      20     707       0       0    2833       0]
 [      4       0    2723       0       0       0  118806]]
\end{lstlisting}


\newpage
\subsubsection{RF Model ID 1 - Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{S-CV Results}!
Mean AUC = 99.99
Mean F1 = 99.66
Mean Precision = 99.66
Mean Recall = 99.67
Mean Accuracy = 99.67
Training Time 7794.549654006958 seconds

!\textbf{Final Test Results}!
Test AUC: 0.9999070506312879
Weighted Test F1: 0.996638797834701
Weighted Test Precision: 0.9966379719195173
Weighted Test Recall: 0.9967196932696956
Test Accuracy: 0.9967196932696956

!\textbf{Classification Report}!
			  precision    recall  f1-score   support

      Botnet       0.95      0.77      0.85     17060
      Malware      0.89      0.82      0.86     39476
      Normal       1.00      1.00      1.00   4572206
         SQL       0.93      0.86      0.89       789
        SSDP       1.00      1.00      1.00   1649955
         SSH       0.94      0.79      0.86      3565
WebsiteSpoof       0.99      0.98      0.98    121533

    accuracy                           1.00   6404584
   macro avg       0.96      0.89      0.92   6404584
weighted avg       1.00      1.00      1.00   6404584
    
!\textbf{Confusion Matrix}!    
[[  13082      17    3957       0       0       2       2]
 [     17   32454    6994       0       0      10       1]
 [    649    3821 4565771      51       2     161    1751]
 [      0       0     113     676       0       0       0]
 [      0       0       2       0 1649953       0       0]
 [      5      20     707       0       0    2833       0]
 [      4       0    2723       0       0       0  118806]]
 
\end{lstlisting}

\newpage
\subsubsection{RF Model ID 2 - Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{Final Test Results}!
Test AUC:  0.9999070506308619
Weighted Test Precision:  0.9966379719195173
Weighted Test Recall:  0.9967196932696956
Weighted Test F1:  0.996638797834701
Test Accuracy:  0.9967196932696956

!\textbf{Classification Report}!
				  precision    recall  f1-score   support

          Botnet       0.95      0.77      0.85     17060
         Malware       0.89      0.82      0.86     39476
          Normal       1.00      1.00      1.00   4572206
   SQL_Injection       0.93      0.86      0.89       789
            SSDP       1.00      1.00      1.00   1649955
             SSH       0.94      0.79      0.86      3565
Website_spoofing       0.99      0.98      0.98    121533

        accuracy                           1.00   6404584
       macro avg       0.96      0.89      0.92   6404584
    weighted avg       1.00      1.00      1.00   6404584
    
!\textbf{Confusion Matrix}!    
[[  13082      17    3957       0       0       2       2]
 [     17   32454    6994       0       0      10       1]
 [    649    3821 4565771      51       2     161    1751]
 [      0       0     113     676       0       0       0]
 [      0       0       2       0 1649953       0       0]
 [      5      20     707       0       0    2833       0]
 [      4       0    2723       0       0       0  118806]]
\end{lstlisting}

\newpage
\subsubsection{RF Model ID 3 - Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{S-CV Results}!
Mean AUC = 0.9999
Mean F1 = 0.9966
Mean Precision = 0.9966
Mean Recall = 0.9967
Mean Accuracy = 0.9967
Training Time 56042.87267756462  seconds

!\textbf{Final Test Results}!
Weighted AUC:  0.9999070506308619
Weighted F1:  0.996638797834701
Weighted Precision:  0.9966379719195173
Weighted Recall:  0.9967196932696956
Accuracy:  0.9967196932696956

!\textbf{Classification Report}!
				  precision    recall  f1-score   support

          Botnet       0.95      0.77      0.85     17060
         Malware       0.89      0.82      0.86     39476
          Normal       1.00      1.00      1.00   4572206
   SQL_Injection       0.93      0.86      0.89       789
            SSDP       1.00      1.00      1.00   1649955
             SSH       0.94      0.79      0.86      3565
Website_spoofing       0.99      0.98      0.98    121533

        accuracy                           1.00   6404584
       macro avg       0.96      0.89      0.92   6404584
    weighted avg       1.00      1.00      1.00   6404584
    
    
!\textbf{Confusion Matrix}!

[[  13082      17    3957       0       0       2       2]
 [     17   32454    6994       0       0      10       1]
 [    649    3821 4565771      51       2     161    1751]
 [      0       0     113     676       0       0       0]
 [      0       0       2       0 1649953       0       0]
 [      5      20     707       0       0    2833       0]
 [      4       0    2723       0       0       0  118806]]
\end{lstlisting}

\newpage
\subsubsection{RF Model ID 4 - Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{S-CV Results}!
Mean AUC = 99.95
Mean F1 = 95.23
Mean Precision = 98.50
Mean Recall = 92.96
Mean Accuracy = 92.96
Training Time = 10147 seconds

!\textbf{Final Test Results}!
Weighted AUC: 0.9994792868436975
Weighted Precision: 0.984757273176817
Weighted Recall: 0.925409987596384
Weighted F1: 0.9496738038716113
Accuracy: 0.925409987596384

!\textbf{Classification Report}!

                     precision    recall  f1-score   support

          Botnet       0.14      0.96      0.24     17060
         Malware       0.22      0.97      0.36     39476
          Normal       1.00      0.90      0.95   4572206
   SQL_Injection       0.01      0.99      0.02       789
            SSDP       1.00      1.00      1.00   1649955
             SSH       0.04      0.99      0.08      3565
Website_spoofing       0.61      0.98      0.75    121533
           
        accuracy                           0.93   6404584
       macro avg       0.43      0.97      0.48   6404584
    weighted avg       0.98      0.93      0.95   6404584
    
    
!\textbf{Confusion Matrix}!

[[  16326      90      30      91       0     504      19]
 [     76   38392      13     170       0     824       1]
 [ 102163  135709 4098890   76381       2   83351   75710]
 [      0       0       1     785       0       3       0]
 [      0       0      10       0 1649945       0       0]
 [      6      15       4      16       0    3523       1]
 [    282    1145     484     262       0     355  119005]]
\end{lstlisting}


\newpage
\subsubsection{RF Model ID 5 - Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{S-CV Results}!
Mean AUC = 0.9987
Mean F1 = 0.9153
Mean Precision = 0.9842
Mean Recall = 0.8665
Mean Accuracy = 0.8665
Training Time 4632.155310869217 seconds

!\textbf{Final Test Results}!
Weighted AUC: 0.998635554230961
Weighted Precision: 0.9848384599880898
Weighted Recall: 0.8600619493787575
Weighted F1: 0.9116563847511311
Accuracy: 0.8600619493787575

!\textbf{Classification Report}!

			  precision    recall  f1-score   support

      Botnet       0.06      0.94      0.12     17060
     Malware       0.10      0.90      0.19     39476
      Normal       1.00      0.81      0.89   4572206
         SQL       0.01      0.99      0.01       789
        SSDP       0.99      1.00      1.00   1649955
         SSH       0.02      0.99      0.04      3565
    WebSpoof       0.76      0.92      0.83    121533

    accuracy                           0.86   6404584
   macro avg       0.42      0.94      0.44   6404584
weighted avg       0.98      0.86      0.91   6404584
    
    
!\textbf{Confusion Matrix}!

[[  16064     141      26     133       0     693       3]
 [     72   35584     121     125       0    3572       2]
 [ 240322  301805 3690025  138640   11696  154013   35705]
 [      0       0       0     783       0       5       1]
 [      0       0       9       0 1649946       0       0]
 [      6       1       0      12       0    3546       0]
 [   4970    1711     301    1392       0     768  112391]]
\end{lstlisting}

% XGBOOOOOOOOOST

\newpage
\subsection{XGBoost}
\label{appx:XGBoost}

\subsubsection{Stock 100\% - XGBoost Raw Metrics}
\begin{lstlisting}[escapechar=!]
!\textbf{Final Test Results}!

Weighted AUC: 99.99
Weighted F1: 99.65
Weighted Precision: 99.65
Weighted Recall: 99.65
Accuracy: 99.65

!\textbf{Classification Report}!

              precision    recall  f1-score   support

           0       0.96      0.74      0.84     17060
           1       0.86      0.85      0.86     39476
           2       1.00      1.00      1.00   4572206
           3       0.93      0.88      0.90       789
           4       1.00      1.00      1.00   1649955
           5       0.95      0.79      0.86      3565
           6       0.99      0.97      0.98    121533

    accuracy                           1.00   6404584
   macro avg       0.95      0.89      0.92   6404584
weighted avg       1.00      1.00      1.00   6404584
    
    
!\textbf{Confusion Matrix}!

[[  12703      31    4320       0       0       2       4]
 [     17   33596    5857       0       0       6       0]
 [    539    5289 4564546      56       0     144    1632]
 [      0       0      91     698       0       0       0]
 [      0       0       0       0 1649955       0       0]
 [      5      15     745       0       0    2800       0]
 [      1       4    3344       0       0       0  118184]]
\end{lstlisting}

\subsubsection{Stock 100\% - XGBoost CM}
\includegraphics[width=\textwidth]{Appendices/Images/XGB/xgb_stock_100_cm.png}


\subsubsection{Stock 100\% - XGBoost Feature Importance}
\includegraphics[width=\textwidth]{Appendices/Images/XGB/xgb_stock_100_feature_importance.png}
\newpage



\section{Neural Networks}
\label{appx: Neural Networks}

\subsection{MLP NN v1}
\label{appx: MLP NN v1}

\begin{lstlisting}[language=Python]
# Create a sequential model
model = Sequential()
input_shape = (X_train_ohe.shape[1],)

# Add layers to the model
model.add(Dense(128, activation='relu', input_shape=input_shape))
model.add(Dense(64, activation='relu'))
model.add(Dense(7, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train_ohe, y_train_ohe, epochs=10, batch_size=32, validation_data=(X_test_ohe, y_test_ohe))

# Evaluate the model using test data
test_loss, test_acc = model.evaluate(X_test_ohe, y_test_ohe)

print('Test accuracy:', test_acc)
\end{lstlisting}

\subsubsection{MLP Neural Network}
\label{appx: MLP NN}

\begin{lstlisting}[language=Python]
from keras.models import Sequential
from keras.layers import Dense, Dropout, BatchNormalization
from keras.optimizers import SGD
from keras.initializers import he_uniform
from keras.metrics import AUC

# Define the number of classes
num_classes = 7

# Define the model architecture
model = Sequential()

# Add the input layer
model.add(Dense(100, input_shape=(X_train_ohe.shape[1],), activation='relu', kernel_initializer=he_uniform()))

# Add batch normalization
model.add(BatchNormalization())

# Add the first hidden layer
model.add(Dense(80, activation='relu', kernel_initializer=he_uniform()))
model.add(Dropout(0.25))
model.add(BatchNormalization())

# Add the second hidden layer
model.add(Dense(60, activation='relu', kernel_initializer=he_uniform()))
model.add(Dropout(0.2))
model.add(BatchNormalization())

# Add the third hidden layer
model.add(Dense(40, activation='relu', kernel_initializer=he_uniform()))
model.add(BatchNormalization())

# Add the fourth hidden layer
model.add(Dense(20, activation='relu', kernel_initializer=he_uniform()))
model.add(BatchNormalization())

# Add the output layer
model.add(Dense(num_classes, activation='softmax'))

# Define the optimizer
sgd = SGD(lr=0.01, momentum=0.9)

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[AUC()])

# Train the model
batch_size = 170
epochs = 10
history = model.fit(X_train_ohe, y_train_ohe, batch_size=batch_size, epochs=epochs, validation_data=(X_test_ohe, y_test_ohe))

# Evaluate the model on your test data
test_loss, test_auc = model.evaluate(X_test_ohe, y_test_ohe)
\end{lstlisting}


\newpage

\end{appendices}


