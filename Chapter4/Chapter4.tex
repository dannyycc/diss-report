 %!TEX root =  ../Report.tex

\section{Experiments}
\label{sec: Experiments}

In this study, a diverse set of machine-learning algorithms were utilised for this problem. Three shallow classifiers: Random Forest, K-Nearest Neighbour and XGBoost and one neural network: Multi-Layered Perceptron.

\subsection{Initial Modelling}
To speed up initial training and testing for each machine learning algorithm, a multitude of subsets of the original combined data were created using sklearn's train\_test\_split to create a stratified split resulting in reduced datasets. Varying levels of data splits were created, including a 50\%, 60\% and 80\% data split from the original ~12 million rows of data as seen in Table \ref{tab:split_data}. The reduced datasets allow for a quicker training time to determine the suitability of each model and helped to provide a rough measure of a model's underlying performance of the data. As discussed previously, where appropriate, additional Cross Validation is used during training to better understand the performance of the model.


\subsection{Parameter Tuning} 
An important aspect of experimentation is the tuning of parameters specific to each model. Hyperparameters are defined during the creation of each model and have a substantial impact on its performance. As such, two primary methods are adopted. In some instances, an exhaustive searching method such as GridSearchCV is initially used to identify the optimal parameters. GridSearchCV uses a user-defined parameter grid and systematically evaluates each combination relative to the model's performance. GridSearchCV can be computationally expensive and time-consuming, due to limitations in both hardware, time and numerous crashes, GridSearchCV was not always used. 

\smallskip

To address this issue, RandomizedSearchCV was adopted, by searching randomly through the parameter grid with a defined number of iterations, a good tradeoff is achieved that provides a balanced and efficient solution without sacrificing quality. Additionally, in some cases and initial experimentation, a combination of iterative experimentation and domain knowledge was used instead. This was justified due to limited time constraints and prior knowledge and understanding of the underlying algorithm. 

