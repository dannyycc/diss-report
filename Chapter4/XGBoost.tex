 \newpage

\subsubsection{XGBoost}
\label{sec:xgboost}

A series of models were trained and this model followed both an exploratory and iterative approach, RandomizedSearchCV was also utilised in the training phase to optimise hyperparameters. Table \ref{tab:xgboost-parameters} shows the parameters used for each model, \textbf{-} denotes that no value was used, i.e., the default value was used.

\begin{table}[h]
  \centering
  \caption{XGBoost Model Parameters}
  \label{tab:xgboost-parameters}
  \begin{tabular}{lcccccc}
    \toprule
    Parameter & Model 0-2\&6 & Model 3 & Model 5 & Model 8 & Model 10 & Model 11 \\
    \midrule
    early\_stopping\_rounds & - & 10 & 10 & 10 & 10 & 10 \\
    subsample & - & - & - & - & 0.9 & - \\
    n\_estimators & - & - & 300 & 300 & 200 & 300 \\
    min\_child\_weight & - & - & - & - & 3 & - \\
    max\_depth & - & - & 5 & 5 & 9 & 5 \\
    learning\_rate & - & - & 0.2 & 0.2 & 0.3 & 0.2 \\
    gamma & - & - & - & - & 0 & - \\
    colsample\_bytree & - & - & - & - & 0.7 & - \\
    reg\_alpha & - & 0.1 & 0.1 & 0.1 & - & 0.1 \\
    \bottomrule
  \end{tabular}
\end{table}


\medskip

Initial experimentation began with the XGBoost classifier being trained with default parameters across a range of subsets of data, 60\%, 80\% and 100\% as shown in models 0, 1 and 6. Additionally, model 1 further incorporated Stratified Cross Validation during training. This was used to establish clear baseline performance of the classifiers and helped to provide context when tuning parameters.

Where available, the VM machine was used for training, allowing XGBoost to maximise its performance on the dedicated GPU. Early stopping and regularisation were added in subsequent models to help avoid the model from overfitting on the training data. e.g. in Model 3 only early stopping and regularisation were added and no noticeable performance increase/decrease was observed. 

\subsubsection*{Parameter Tuning}

An attempt was made to utilise GridSearchCV for parameter optimisation; significant setbacks were encountered in achieving a successful execution due to numerous errors, system crashes, and exceptionally high grid search time. In light of the difficulties faced with GridSearchCV, RandomizedSearchCV was utilised. 

Despite challenges faced with GridSearchCV, initial experimentation with 5 CV on a smaller parameter grid on the 80\% dataset was successful and subsequent parameters were tested with models 5 and 8. An additional RandomizedSearchCV was run on the entire dataset and combined with stratified 10-fold cross-validation to ensure the best-found parameters were verified and proved consistent across the 10 folds.

See Listing \ref{lst:param_grid_xgb} for the parameter grids used.

\medskip
	
\begin{lstlisting}[language=Python, caption={Grid Search Parameters For XGBoost}, label= lst:param_grid_xgb]

gscv_param_grid = {
    'learning_rate': [0.05, 0.1, 0.2],
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5]
}

rgs_param_grid = {
    'learning_rate': [0.01, 0.1, 0.3],
    'max_depth': [3, 6, 9],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2],
    'subsample': [0.5, 0.7, 0.9],
    'colsample_bytree': [0.5, 0.7, 0.9],
    'n_estimators': [100, 200]
}
\end{lstlisting}

\begin{table}[H]
\captionsetup{justification=centering} 
\centering
\caption{XGBoost GridSearch Parameters}
\begin{tabular}{lll}
\hline
\textbf{Parameter} & \textbf{GS} & \textbf{RGS} \\ \hline
Early Stopping & - & 10 \\
Evaluation Metric & merror & merror \\
Learning Rate & 0.2 & 0.3 \\
Max Depth & 5 & 9 \\
Min Child Weight & - & 3 \\
Gamma & - & 0 \\
Subsamples & - & 0.9 \\
Colsample By Tree & - & 0.7 \\
N Estimators & 300 &  200 \\ \hline
\end{tabular}
\label{tab:xg_gs_parameters}
\end{table}

\textbf{Best Found Parameters}
\medskip

The parameter tuning process helped to identify a set of optimal parameters using RandomisedSearchCV, as detailed in Table \ref{tab:xg_gs_parameters}. These parameters were used to create Model 10. Subsequent models created afterwards, from additional parameter tuning did not show a sign of noticeable improvement in the model's performance. Due to limited time and computational power, further parameter tuning was not performed, and the decision was made here to stop further experiments.
